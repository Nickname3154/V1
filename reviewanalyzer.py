import streamlit as st
import time
from collections import Counter

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, PreTrainedTokenizerFast, BartForConditionalGeneration


@st.cache_resource
def load_sentiment_pipeline():
    model_name = "beomi/KcELECTRA-base"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)


@st.cache_resource
def load_summarizer():
    model_name = "digit82/kobart-summarization"
    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
    model = BartForConditionalGeneration.from_pretrained(model_name)
    return tokenizer, model


def get_coupang_reviews(product_url, max_reviews=30):
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(product_url)
    time.sleep(3)

    try:
        review_tab = driver.find_element(By.XPATH, '//a[contains(@href, "review")]')
        review_tab.click()
        time.sleep(3)

        reviews = []
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_tries = 0

        while len(reviews) < max_reviews and scroll_tries < 10:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            review_elements = driver.find_elements(By.CLASS_NAME, "sdp-review__article__list__review__content")

            for elem in review_elements:
                text = elem.text.strip()
                if text and text not in reviews:
                    reviews.append(text)
                if len(reviews) >= max_reviews:
                    break

            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            scroll_tries += 1

        return reviews[:max_reviews]

    finally:
        driver.quit()


def summarize_reviews(reviews, tokenizer, model):
    text = " ".join(reviews)
    input_ids = tokenizer.encode(text, return_tensors="pt", max_length=1024, truncation=True)
    summary_ids = model.generate(input_ids, max_length=128, min_length=30, length_penalty=2.0, num_beams=4)
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)


def analyze_sentiment(reviews, sentiment_pipeline):
    results = sentiment_pipeline(reviews)
    labels = [r['label'] for r in results]
    return Counter(labels)


# Streamlit UI
st.set_page_config(page_title="ì¿ íŒ¡ ë¦¬ë·° ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ›ï¸ ì¿ íŒ¡ ìƒí’ˆ ë¦¬ë·° ìš”ì•½ ë° ê°ì • ë¶„ì„")

product_url = st.text_input("ì¿ íŒ¡ ìƒí’ˆ URL", placeholder="https://www.coupang.com/vp/products/XXXX")
max_reviews = st.slider("ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ìˆ˜", 10, 100, 30)

if st.button("ë¶„ì„ ì‹œì‘") and product_url:
    with st.spinner("ğŸ”„ ë¦¬ë·° ìˆ˜ì§‘ ì¤‘..."):
        reviews = get_coupang_reviews(product_url, max_reviews=max_reviews)
        st.success(f"âœ… {len(reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ")

    with st.spinner("ğŸ” ê°ì • ë¶„ì„ ì¤‘..."):
        sentiment_pipeline = load_sentiment_pipeline()
        sentiment_result = analyze_sentiment(reviews, sentiment_pipeline)
        st.subheader("ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼")
        for label, count in sentiment_result.items():
            st.write(f"{label}: {count}ê°œ")

    with st.spinner("ğŸ“ ë¦¬ë·° ìš”ì•½ ì¤‘..."):
        tokenizer, model = load_summarizer()
        summary = summarize_reviews(reviews, tokenizer, model)
        st.subheader("ğŸ§¾ ë¦¬ë·° ìš”ì•½")
        st.write(summary)

else:
    st.info("ì¿ íŒ¡ ìƒí’ˆ URLì„ ì…ë ¥í•œ ë’¤ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
